{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "%matplotlib inline \n",
    "\n",
    "#TODO : CHANGE ACCORDING TO NEEDS\n",
    "imported_data=True # True if data/... already exists\n",
    "evaluation=True # True if want to evaluate error of machine learning algo\n",
    "submit=True # True if want to replace submission file by new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import data if not already done\n",
    "if (not imported_data) : \n",
    "    import ImportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BEGINNING OF LEARNING CODE\n",
    "# Read submission data\n",
    "submission = pd.read_csv('submission.txt', sep='\\t')\n",
    "\n",
    "# Stock list of services to predict\n",
    "ass_list=submission['ASS_ASSIGNMENT'].unique()\n",
    "\n",
    "# Imports data into dictionary\n",
    "data = {}\n",
    "for x in ass_list : \n",
    "    data[x] = np.load('data/'+x+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding features\n",
    "# Can choose to add more features if desired! \n",
    "\n",
    "# add_features() changes structure of data[x] where x is a service name :\n",
    "# date (timestamp) / number of calls / day of week / month / time\n",
    "# time is from 0 to 47 (hour*2+minutes/30)\n",
    "def add_features(): \n",
    "    print(\"Features added for : \")\n",
    "    for x in ass_list :\n",
    "        # Initialize two columns of zero\n",
    "        n=np.shape(data[x])[0]\n",
    "        z=np.zeros((n,3),int) \n",
    "        \n",
    "        # Append zero column twice\n",
    "        data[x]=np.append(data[x],z,axis=1)\n",
    "\n",
    "        # Addding Columns : Day of week / Month\n",
    "        for i in range(n) :\n",
    "            data[x][i,2]=pd.to_datetime(data[x][i,0]).weekday()\n",
    "            data[x][i,3]=data[x][i,0].month\n",
    "            data[x][i,4]=int((2*data[x][i,0].hour)+(data[x][i,0].minute/30))\n",
    "            \n",
    "        if (x!='Prestataires') : \n",
    "            print(x, end=\", \")\n",
    "        else : \n",
    "            print(x)\n",
    "        # TODO IMPROVE\n",
    "        # - possibly much faster if adding features in dataframe\n",
    "        # - Label Binarizer - change magnitude of day of week, month, hour\n",
    "        #                     to 7, 31, 48 columns of 0 and 1s respectively\n",
    "        \n",
    "# del_features deletes everything from column 2\n",
    "def del_features():\n",
    "    for x in ass_list :\n",
    "        data[x]=np.delete(data[x],np.s_[2:np.shape(data[x])[1]],1)\n",
    "        \n",
    "del_features()\n",
    "add_features()\n",
    "#print(data[ass_list[0]][::1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df={}\n",
    "for x in ass_list : \n",
    "    df[x]=pd.DataFrame.from_dict(data[x])\n",
    "    df[x].columns=['DATETIME','CALLS','DAY','MONTH','TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data is ambient dictionary in this script\n",
    "\n",
    "# predict_single_week takes in \"dates\" which is a list of timestamps (continuous)\n",
    "# Assume dates given in groups of weeks, take minimum of dates. \n",
    "# predict_single_week returns a dictionary predicted where:\n",
    "# keys = services, values = numpy arrays (TimeStamp, Calls Received)\n",
    "\n",
    "def predict_single_week(dates) : \n",
    "    #Initialize and clear dictionary to return\n",
    "    predicted={}\n",
    "    predicted.clear()\n",
    "    \n",
    "    # X and Y restocks df as information needed to predict and calls, until min date\n",
    "    \n",
    "    # Assume dates given in groups of weeks, take minimum of dates. \n",
    "    min_date = min(dates)\n",
    "    X={}\n",
    "    Y={}\n",
    "    est={}\n",
    "    \n",
    "    for x in ass_list : \n",
    "        X[x]=df[x][['DAY','MONTH','TIME']][df[x]['DATETIME']<pd.to_datetime(min_date)].as_matrix()\n",
    "        Y[x]=df[x]['CALLS'][df[x]['DATETIME']<pd.to_datetime(min_date)].as_matrix()\n",
    "    \n",
    "    # TODO : CODE HERE\n",
    "    \n",
    "    #from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    # Creating each predictor\n",
    "    #for x in ass_list : \n",
    "    #    clf=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0, loss='ls')\n",
    "    #    est[x] = clf.fit(X[x], Y[x])\n",
    "    \n",
    "    \n",
    "    # Creating X_test from dates that has all information needed\n",
    "    #X_test=np.zeros((len(dates),3),int)\n",
    "\n",
    "    #for i in range(len(dates)) :\n",
    "    #    X_test[i,0]=dates[i].weekday()\n",
    "    #    X_test[i,1]=dates[i].month\n",
    "    #    X_test[i,2]=int((2*dates[i].hour)+(dates[i].minute/30))\n",
    "\n",
    "    # Calculating y_test for each predictor\n",
    "    #y_test={}\n",
    "    #for x in ass_list : \n",
    "        # Round up always\n",
    "        #y_test[x]=np.ceil(est[x].predict(X_test)).astype(int)\n",
    "        # Make sure all positive\n",
    "        #y_test[x]=y_test[x]*(y_test[x]>0)\n",
    "        #predicted[x]=np.append(np.reshape(dates,(len(dates),1)),np.reshape(y_test[x],(len(dates),1)),axis=1)\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function dates_to_datetime creates datetime stamps at every half hour from a list of date\n",
    "def dates_to_datetime(dates) : \n",
    "    datetimes=[]\n",
    "    times=[\"00:00:00.000\", \"00:30:00.000\", \"01:00:00.000\", \"01:30:00.000\", \n",
    "           \"02:00:00.000\", \"02:30:00.000\", \"03:00:00.000\", \"03:30:00.000\", \n",
    "           \"04:00:00.000\", \"04:30:00.000\", \"05:00:00.000\", \"05:30:00.000\", \n",
    "           \"06:00:00.000\", \"06:30:00.000\", \"07:00:00.000\", \"07:30:00.000\", \n",
    "           \"08:00:00.000\", \"08:30:00.000\", \"09:00:00.000\", \"09:30:00.000\", \n",
    "           \"10:00:00.000\", \"10:30:00.000\", \"11:00:00.000\", \"11:30:00.000\", \n",
    "           \"12:00:00.000\", \"12:30:00.000\", \"13:00:00.000\", \"13:30:00.000\", \n",
    "           \"14:00:00.000\", \"14:30:00.000\", \"15:00:00.000\", \"15:30:00.000\", \n",
    "           \"16:00:00.000\", \"16:30:00.000\", \"17:00:00.000\", \"17:30:00.000\", \n",
    "           \"18:00:00.000\", \"18:30:00.000\", \"19:00:00.000\", \"19:30:00.000\", \n",
    "           \"20:00:00.000\", \"20:30:00.000\", \"21:00:00.000\", \"21:30:00.000\", \n",
    "           \"22:00:00.000\", \"22:30:00.000\", \"23:00:00.000\", \"23:30:00.000\"]\n",
    "    for date in dates : \n",
    "        for time in times : \n",
    "            datetime_entry=str(date+' '+time)\n",
    "            datetimes.append(datetime.strptime(datetime_entry, \"%Y-%m-%d %H:%M:%S.%f\"),)\n",
    "    return datetimes\n",
    "\n",
    "# Split list of dates into list of (weeks=list of datetimes)\n",
    "def dates_to_weeks(dates):\n",
    "    weeks=[]\n",
    "    week=[]\n",
    "    current_wk=0\n",
    "\n",
    "    for date in dates : \n",
    "        if (len(week)==0) :\n",
    "            week.append(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "\n",
    "        elif (len(week)==14*48):\n",
    "            weeks.append(week)\n",
    "            week=[]\n",
    "\n",
    "        else : \n",
    "            current_wk = week[-1].isocalendar()[:2]\n",
    "\n",
    "            if (current_wk[1]==52) :\n",
    "                next_wk=(current_wk[0]+1,1)\n",
    "            else : \n",
    "                next_wk=(current_wk[0],current_wk[1]+1)\n",
    "\n",
    "\n",
    "            if ((datetime.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\").isocalendar()[:2]==current_wk)or(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\").isocalendar()[:2]==next_wk)) :\n",
    "                week.append(datetime.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "            else :\n",
    "                weeks.append(week)\n",
    "                week=[]\n",
    "    return weeks\n",
    "\n",
    "\n",
    "# Error function as defined in project\n",
    "def linex(y_true,y_pred) : \n",
    "    a=0.1\n",
    "    assert(len(y_true)==len(y_pred))\n",
    "    diff=np.subtract(y_true,y_pred)\n",
    "    return np.exp(a*diff)-a*diff-np.ones(len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict for each week in list, append all predicted\n",
    "def predict(dates) : \n",
    "    weeks=dates_to_weeks(dates)\n",
    "    predicted={}\n",
    "\n",
    "    for week in weeks : \n",
    "        print(\"Predicting : \", end='')\n",
    "        print(week[-1].isocalendar()[:2])\n",
    "        predicted_week=predict_single_week(week)\n",
    "\n",
    "        for x in ass_list : \n",
    "            if (x in predicted) :\n",
    "                predicted[x]=np.concatenate((predicted[x], predicted_week[x]), axis=0)\n",
    "            else :\n",
    "                predicted[x]=predicted_week[x]\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EVALUATION\n",
    "if (evaluation) : \n",
    "    # EXAMPLE DATE\n",
    "    dates = ['2011-12-28', '2011-12-29', '2011-12-30', '2011-12-31', '2012-01-01', '2012-01-02', '2012-01-03']\n",
    "    fulldates=dates_to_datetime(dates) #with timestamps, for predict function\n",
    "    \n",
    "    # Call predict\n",
    "    predicted=predict(fulldates)\n",
    "\n",
    "    # Dictionaries for true and predicted values\n",
    "    y_true={}\n",
    "    y_pred={}\n",
    "    y_true.clear()\n",
    "    y_pred.clear()\n",
    "    err={}\n",
    "    err.clear()\n",
    "    err_tot=0\n",
    "    len_tot=0\n",
    "    \n",
    "    # Stocking and printing error by service where there is data\n",
    "    for x in ass_list : \n",
    "        y_true[x]=[]\n",
    "        y_pred[x]=[]\n",
    "        print(\"Evaluating error for : \"+x)\n",
    "        for t in fulldates : # for date\n",
    "            for i in range(len(data[x])) : \n",
    "                if (data[x][i,0]==t) : # if date found in original data\n",
    "                    y_true[x].append(data[x][i,1])\n",
    "                    for j in range(len(predicted[x])) : #find date in predicted\n",
    "                        if (str(predicted[x][j,0])==str(t)) : \n",
    "                            y_pred[x].append(predicted[x][j,1])\n",
    "                            break # add predicted one time\n",
    "                    break # add original one time\n",
    "        err[x]=linex(y_true[x],y_pred[x])\n",
    "        err_tot+=np.sum(err[x])\n",
    "        len_tot+=len(err[x])\n",
    "        #print(\"vector error : \")\n",
    "        #print(err[x])\n",
    "        print(\"error : \")\n",
    "        print(np.sum(err[x]))\n",
    "        print()\n",
    "    print(\"total error : \")\n",
    "    print(err_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualization of original vs predicted for evaluation range\n",
    "if (evaluation):\n",
    "    df2={}\n",
    "    mean={}\n",
    "\n",
    "    for x in ass_list : \n",
    "        print(x)\n",
    "        #Original is green\n",
    "        df2[x]=df[x][['DATETIME','CALLS']][df[x]['DATETIME'].isin(predicted[x][:,0])].as_matrix()\n",
    "        plt.plot(df2[x][:,0],df2[x][:,1],'g')\n",
    "\n",
    "        #Predicted is red\n",
    "        plt.plot(predicted[x][:,0],predicted[x][:,1],'r')\n",
    "\n",
    "        #Mean is blue\n",
    "        #mean[x]=[]\n",
    "        #for i in range(48) : # For each hour\n",
    "        #     mean[x]=np.append(mean[x],(df[x]['CALLS'][df[x]['TIME']==i].mean()))\n",
    "        #mean[x]=np.tile(mean[x],len(predicted[x][:,0])/48)\n",
    "\n",
    "        #plt.plot(predicted[x][:,0],mean[x],'b')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# UPDATE SUBMISSIONS.TXT\n",
    "# ASS_ASSIGNMENT : because not every service appears at any time, \n",
    "# have to check values exist in submissions.txt that we received,\n",
    "# we cannot construct new dataframe directly from predicted\n",
    "\n",
    "if (submit) : \n",
    "    # List of dates in submission.txt\n",
    "    dates=submission['DATE'].unique()\n",
    "    \n",
    "    # Call predict function on weeks\n",
    "    predicted=predict(dates)\n",
    "    \n",
    "    #Rewrite submissions dataframe\n",
    "    for x in ass_list : \n",
    "        print(\"Stocking predictions for \"+x)\n",
    "        if (x in predicted) : # x=assignment\n",
    "            for row in predicted[x] : # row=[date,calls]\n",
    "                # Convert timestamp to yyyy-mm-dd hh:mm:ss.xxx\n",
    "                date = row[0].strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "                # Replace values in submission dsataframe\n",
    "                #better way to loop through this?\n",
    "                submission.loc[(submission['DATE']==date)&(submission['ASS_ASSIGNMENT']==x), ['prediction']]=row[1]\n",
    "\n",
    "    # EXPORT to submission.txt \n",
    "    fh = open(\"submission1.txt\",\"w\")\n",
    "    fh.write(\"DATE\\tASS_ASSIGNMENT\\tprediction\")\n",
    "    for index, row in submission.iterrows(): \n",
    "        fh.write(\"\\n\")\n",
    "        fh.write(str(row[0])+'\\t'+str(row[1])+'\\t'+str(row[2]))\n",
    "    fh.close()\n",
    "    print(\"Text file written!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
